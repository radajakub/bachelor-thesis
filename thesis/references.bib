@book{aima, place={Upper Saddle River, NJ}, edition={3}, title={Artificial intelligence: A modern approach}, ISBN={9780136042594}, publisher={Pearson}, author={Russell, Stuart and Norvig, Peter}, year={2009}}

@book{multiagent, place={Cambridge}, title={Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations}, DOI={10.1017/CBO9780511811654}, publisher={Cambridge University Press}, author={Shoham, Yoav and Leyton-Brown, Kevin}, year={2008}}

@article{osposgs, author = {Karel Horák and Branislav Bošanský and Michal Pěchouček}, title = {Heuristic Search Value Iteration for One-Sided Partially Observable Stochastic Games}, conference = {AAAI Conference on Artificial Intelligence}, year = {2017}, keywords = {}, abstract = {Security problems can be modeled as two-player partially observable stochastic games with one-sided partial observability and infinite horizon (one-sided POSGs). We seek for optimal strategies of player 1 that correspond to robust strategies against the worst-case opponent (player 2) that is assumed to have a perfect information about the game. We present a novel algorithm for approximately solving one-sided POSGs based on the heuristic search value iteration (HSVI) for POMDPs. Our results include (1) theoretical properties of one-sided POSGs and their value functions, (2) guarantees showing the convergence of our algorithm to optimal strategies, and (3) practical demonstration of applicability and scalability of our algorithm on three different domains: pursuit-evasion, patrolling, and search games.}, url = {https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14739}}

@article{poposgs, title={Solving Partially Observable Stochastic Games with Public Observations}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4032}, DOI={10.1609/aaai.v33i01.33012029}, abstractNote={&lt;p&gt;In many real-world problems, there is a dynamic interaction between competitive agents. Partially observable stochastic games (POSGs) are among the most general formal models that capture such dynamic scenarios. The model captures stochastic events, partial information of players about the environment, and the scenario does not have a fixed horizon. Solving POSGs in the most general setting is intractable.Therefore, the research has been focused on subclasses of POSGs that have a value of the game and admit designing (approximate) optimal algorithms. We propose such a subclass for two-player zero-sum games with discounted-sum objective function—POSGs with &lt;em&gt;public observations&lt;/em&gt; (POPOSGs)—where each player is able to reconstruct beliefs of the other player over the unobserved states. Our results include: (1) theoretical analysis of PO-POSGs and their value functions showing convexity (concavity) in beliefs of maximizing (minimizing) player, (2) a novel algorithm for approximating the value of the game, and (3) a practical demonstration of scalability of our algorithm. Experimental results show that our algorithm can closely approximate the value of non-trivial games with hundreds of states.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Horák, Karel and Bošanský, Branislav}, year={2019}, month={Jul.}, pages={2029-2036} }

@article{avectors, ISSN = {0030364X, 15265463}, URL = {http://www.jstor.org/stable/169635}, abstract = {This paper treats the discounted cost, optimal control problem for Markov processes with incomplete state information. The optimization approach for these partially observable Markov processes is a generalization of the well-known policy iteration technique for finding optimal stationary policies for completely observable Markov processes. The state space for the problem is the space of state occupancy probability distributions (the unit simplex). The development of the algorithm introduces several new ideas, including the class of finitely transient policies, which are shown to possess piecewise linear cost functions. The paper develops easily implemented approximations to stationary policies based on these finitely transient policies and shows that the concave hull of an approximation can be included in the well-known Howard policy improvement algorithm with subsequent convergence. The paper closes with a detailed example illustrating the application of the algorithm to the two-state partially observable Markov process.}, author = {Edward J. Sondik}, journal = {Operations Research}, number = {2}, pages = {282--304}, publisher = {INFORMS}, title = {The Optimal Control of Partially Observable Markov Processes Over the Infinite Horizon: Discounted Costs}, urldate = {2022-04-27}, volume = {26}, year = {1978}}

@inproceedings{hsvi, author = {Smith, Trey and Simmons, Reid}, title = {Heuristic Search Value Iteration for POMDPs}, year = {2004}, isbn = {0974903906}, publisher = {AUAI Press}, address = {Arlington, Virginia, USA}, abstract = {We present a novel POMDP planning algorithm called heuristic search value iteration (HSVI). HSVI is an anytime algorithm that returns a policy and a provable bound on its regret with respect to the optimal policy. HSVI gets its power by combining two well-known techniques: attention-focusing search heuristics and piecewise linear convex representations of the value function. HSVI's soundness and convergence have been proven. On some bench-mark problems from the literature, HSVI displays speedups of greater than 100 with respect to other state-of-the-art POMDP value iteration algorithms. We also apply HSVI to a new rover exploration problem 10 times larger than most POMDP problems in the literature.}, booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence}, pages = {520–527}, numpages = {8}, location = {Banff, Canada}, series = {UAI '04}}

@article{exp3formula,  author={Cowling, Peter I. and Powley, Edward J. and Whitehouse, Daniel},  journal={IEEE Transactions on Computational Intelligence and AI in Games},   title={Information Set Monte Carlo Tree Search},   year={2012},  volume={4},  number={2},  pages={120-143},  doi={10.1109/TCIAIG.2012.2200894}}

@misc{minimax, title={Zur Theorie der Gesellschaftsspiele}, volume={100}, url={http://dx.doi.org/10.1007/BF01448847}, DOI={10.1007/bf01448847}, number={1}, journal={Mathematische Annalen}, publisher={Springer Science and Business Media LLC}, author={v. Neumann, J.}, year={1928}, month={Dec}, pages={295–320} } 

@misc{nash, title={Equilibrium points in n -person games}, volume={36}, url={http://dx.doi.org/10.1073/pnas.36.1.48}, DOI={10.1073/pnas.36.1.48}, number={1}, journal={Proceedings of the National Academy of Sciences}, publisher={Proceedings of the National Academy of Sciences}, author={Nash, John F., Jr.}, year={1950}, month={Jan}, pages={48–49} }

@misc{zermelo, title={Zermelo 1913}, url={http://dx.doi.org/10.1007/978-3-540-79384-7_9}, DOI={10.1007/978-3-540-79384-7_9}, journal={Ernst Zermelo - Collected Works/Gesammelte Werke}, publisher={Springer Berlin Heidelberg}, author={Larson, Paul B.}, year={2010}, pages={260–273} } 

@misc{shapley, title={Stochastic Games}, volume={39}, url={http://dx.doi.org/10.1073/pnas.39.10.1095}, DOI={10.1073/pnas.39.10.1095}, number={10}, journal={Proceedings of the National Academy of Sciences}, publisher={Proceedings of the National Academy of Sciences}, author={Shapley, L. S.}, year={1953}, month={Oct}, pages={1095–1100} } 

@article{posg, place = {NL}, title = {Structure in the Value Function of Two-Player Zero-Sum Games of Incomplete Information}, volume = {285}, ISSN = {0922-6389}, url = {https://doi.org/10.3233/978-1-61499-672-9-1628}, DOI = {10.3233/978-1-61499-672-9-1628}, abstractNote = {In this paper,  we introduce a new formulation for the value function of a zero-sum Partially Observable Stochastic Game (zs-POSG) in terms of a &lsquo;plan-time sufficient statistic&rsquo;,  a distribution over joint sets of information. We prove that this value function exhibits concavity and convexity with respect to appropriately chosen subspaces of the statistic space. We anticipate that this result is a key pre-cursor for developing solution methods that exploit such structure. Finally,  we show that the formulation allow us to reduce a finite zs-POSG to a &lsquo;centralized&rsquo; model with shared observations,  thereby transferring results for the latter (narrower) class of games to games with individual observations.}, number = {ECAI 2016}, journal = {Frontiers in Artificial Intelligence and Applications}, publisher = {IOS Press}, author = {Wiggers Auke J. and Oliehoek Frans A. and Roijers Diederik M.}, year = {2016}, pages = {1628–1629}}

@misc{bandits, doi = {10.48550/ARXIV.1904.07272}, url = {https://arxiv.org/abs/1904.07272}, author = {Slivkins, Aleksandrs}, keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Data Structures and Algorithms (cs.DS), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}, title = {Introduction to Multi-Armed Bandits}, publisher = {arXiv}, year = {2019}, copyright = {arXiv.org perpetual, non-exclusive license}}

@misc{rlselfplay, doi = {10.48550/ARXIV.2006.12007}, url = {https://arxiv.org/abs/2006.12007}, author = {Bai, Yu and Jin, Chi and Yu, Tiancheng}, keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}, title = {Near-Optimal Reinforcement Learning with Self-Play}, publisher = {arXiv}, year = {2020}, copyright = {arXiv.org perpetual, non-exclusive license}}

@phdthesis{poposgsthesis, author  = {Karel Horák}, title   = {Scalable Algorithms for Solving Stochastic Games with Limited Partial Observability}, school  = {Czech Technical University in Prague. Computing and Information Centre.}, year    = {2020}, month   = {jan}}

@mastersthesis{exp3alg, author  = {Klíma Richard}, title   = {Combining online learning and equilibrium computation in security games}, school  = {Czech Technical University in Prague. Computing and Information Centre.}, year    = {2015}}

@misc{halmir, author={Metacentrum}, title={Resources}, note={ \url{https://metavo.metacentrum.cz/pbsmon2/resource/halmir.metacentrum.cz/}, Last accessed on 06-05-2022}}

@article{julia, author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.}, title = {Julia: A Fresh Approach to Numerical Computing}, journal = {SIAM Review}, volume = {59}, number = {1}, pages = {65-98}, year = {2017}, doi = {10.1137/141000671}, URL = {https://doi.org/10.1137/141000671}, eprint = {https://doi.org/10.1137/141000671}, abstract = { Bridging cultures that have often been distant, Julia combines expertise from the diverse fields of computer science and computational science to create a new approach to numerical computing. Julia is designed to be easy and fast and questions notions generally held to be “laws of nature" by practitioners of numerical computing: \beginlist \item High-level dynamic programs have to be slow. \item One must prototype in one language and then rewrite in another language for speed or deployment. \item There are parts of a system appropriate for the programmer, and other parts that are best left untouched as they have been built by the experts. \endlist We introduce the Julia programming language and its design---a dance between specialization and abstraction. Specialization allows for custom treatment. Multiple dispatch, a technique from computer science, picks the right algorithm for the right circumstance. Abstraction, which is what good computation is really about, recognizes what remains the same after differences are stripped away. Abstractions in mathematics are captured as code through another technique from computer science, generic programming. Julia shows that one can achieve machine performance without sacrificing human convenience. } }

@article{peg1, doi = {10.1007/s10514-011-9241-4}, url = {https://doi.org/10.1007/s10514-011-9241-4}, year = {2011}, month = jul, publisher = {Springer Science and Business Media {LLC}}, volume = {31}, number = {4}, pages = {299--316}, author = {Timothy H. Chung and Geoffrey A. Hollinger and Volkan Isler}, title = {Search and pursuit-evasion in mobile robotics}, journal = {Autonomous Robots}}

@software{clp, author = {John Forrest and Stefan Vigerske and Ted Ralphs and Lou Hafer and John Forrest and jpfasano and Haroldo Gambini Santos and Matthew Saltzman and Jan-Willem and Bjarni Kristjansson and h-i-gassmann and Alan King and pobonomo and Samuel Brito and to-st}, title = {coin-or/Clp: Release releases/1.17.7}, month = jan, year = 2022, publisher = {Zenodo}, version = {releases/1.17.7}, doi = {10.5281/zenodo.5839302}, url = {https://doi.org/10.5281/zenodo.5839302}}

@misc{pomdp_applications, author = {Anthony R. Cassandra}, title = {A Survey of POMDP Applications}, year = {}}

@article{mdp_applications, ISSN = {00922102, 1526551X}, URL = {http://www.jstor.org/stable/25060766}, abstract = {In the first few years of an ongoing survey of applications of Markov decision processes where the results have been implemented or have had some influence on decisions, few applications have been identified where the results have been implemented but there appears to be an increasing effort to model many phenomena as Markov decision processes.}, author = {Douglas J. White}, journal = {Interfaces}, number = {6}, pages = {73--83}, publisher = {INFORMS}, title = {Real Applications of Markov Decision Processes}, urldate = {2022-05-18}, volume = {15}, year = {1985}}

@inproceedings{games_market_trading,  author={Greenwood, Garrison W. and Tymerski, Richard},  booktitle={2008 IEEE Symposium On Computational Intelligence and Games},   title={A game-theoretical approach for designing market trading strategies},   year={2008},  volume={},  number={},  pages={316-322},  doi={10.1109/CIG.2008.5035656}}

@article{games_bio, doi = {10.1098/rspb.2016.0847}, url = {https://doi.org/10.1098/rspb.2016.0847}, year = {2016}, month = sep, publisher = {The Royal Society}, volume = {283}, number = {1838}, pages = {20160847}, author = {Joel S. Brown}, title = {Why Darwin would have loved evolutionary game theory}, journal = {Proceedings of the Royal Society B: Biological Sciences}}

@article{games_deeplearning, doi = {10.1007/s11042-022-12153-2}, url = {https://doi.org/10.1007/s11042-022-12153-2}, year = {2022}, month = feb, publisher = {Springer Science and Business Media {LLC}}, volume = {81}, number = {6}, pages = {8963--8994}, author = {Tanmoy Hazra and Kushal Anjaria}, title = {Applications of game theory in deep learning: a survey}, journal = {Multimedia Tools and Applications}}

@inprocedings{games_cloud,  author={Jain, Ashima and Tripathi, Khushboo and Jatain, Aman and Chaudhary, Manju},  booktitle={2022 9th International Conference on Computing for Sustainable Global Development (INDIACom)},   title={A Game Theory based Attacker Defender Model for IDS in Cloud Security},   year={2022},  volume={},  number={},  pages={190-194},  doi={10.23919/INDIACom54597.2022.9763191}}

@article{games_blockchain,  author={Liu, Ziyao and Luong, Nguyen Cong and Wang, Wenbo and Niyato, Dusit and Wang, Ping and Liang, Ying-Chang and Kim, Dong In},  journal={IEEE Access},   title={A Survey on Blockchain: A Game Theoretical Perspective},   year={2019},  volume={7},  number={},  pages={47615-47643},  doi={10.1109/ACCESS.2019.2909924}}

@misc{gitlab, title={{https://gitlab.fel.cvut.cz/brozjak2/HSVIforOneSidedPOSGs.jl}}, author={Brož, Jakub and Kubíček, Ondřej}}
